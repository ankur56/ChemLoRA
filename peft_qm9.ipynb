{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/g/m/gmerz2/miniconda3/envs/chemGPT/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from gptchem.gpt_classifier import GPTClassifier\n",
    "from gptchem.tuner import Tuner\n",
    "from gptchem.formatter import RegressionFormatter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pycm import ConfusionMatrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING = {\n",
    "    \"t5\": [\"q\", \"v\"],\n",
    "    \"mt5\": [\"q\", \"v\"],\n",
    "    \"bart\": [\"q_proj\", \"v_proj\"],\n",
    "    \"gpt2\": [\"c_attn\"],\n",
    "    \"bloom\": [\"query_key_value\"],\n",
    "    \"blip-2\": [\"q\", \"v\", \"q_proj\", \"v_proj\"],\n",
    "    \"opt\": [\"q_proj\", \"v_proj\"],\n",
    "    \"gptj\": [\"q_proj\", \"v_proj\"],\n",
    "    \"gpt_neox\": [\"query_key_value\"],\n",
    "    \"gpt_neo\": [\"q_proj\", \"v_proj\"],\n",
    "    \"bert\": [\"query\", \"value\"],\n",
    "    \"roberta\": [\"query\", \"value\"],\n",
    "    \"xlm-roberta\": [\"query\", \"value\"],\n",
    "    \"electra\": [\"query\", \"value\"],\n",
    "    \"deberta-v2\": [\"query_proj\", \"value_proj\"],\n",
    "    \"deberta\": [\"in_proj\"],\n",
    "    \"layoutlm\": [\"query\", \"value\"],\n",
    "    \"llama\": [\"q_proj\", \"v_proj\"],\n",
    "    \"chatglm\": [\"query_key_value\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, EarlyStoppingCallback\n",
    "import os\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "def get_data():\n",
    "    with open(\"qm9_key_smiles_0_val_u0_atom_b3lyp.pickle\", 'rb') as pickle_file:\n",
    "        pickled_data=pickle.load(pickle_file)\n",
    "    raw_data = pd.DataFrame(list(pickled_data.items()), columns=[\"SMILES\", \"B3LYP atomization energy in kcal/mol\"])\n",
    "    formatter = RegressionFormatter(representation_column='SMILES',\n",
    "        label_column='B3LYP atomization energy in kcal/mol',\n",
    "        property_name='atomization energy in kcal/mol',\n",
    "        num_digits=4\n",
    "        )\n",
    "    data = formatter.format_many(raw_data).drop(columns=[\"label\",\"representation\"], axis=1)\n",
    "    train_size=round(0.8*len(data))\n",
    "    val_size=round((len(data)-train_size)/2)\n",
    "    test_size=len(data)-train_size-val_size\n",
    "    df_trainval, df_test = train_test_split(data, test_size=val_size, train_size=train_size, random_state=42)\n",
    "    df_train, df_val = train_test_split(df_trainval,test_size=test_size, shuffle=True)\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    #dataframes\n",
    "    df_train: pd.DataFrame,\n",
    "    df_val: pd.DataFrame,\n",
    "    # model/data params\n",
    "    base_model: str = \"gpt2\",  # the only required argument\n",
    "    data_path: str = \"qm9_key_smiles_0_val_u0_atom_b3lyp.pickle\",\n",
    "    output_dir: str = \"outputs\",\n",
    "    # training hyperparams\n",
    "    batch_size: int = 1024,\n",
    "    micro_batch_size: int = 64,\n",
    "    num_epochs: int = 3,\n",
    "    learning_rate: float = 3e-4,\n",
    "    cutoff_len: int = 256,\n",
    "    # lora hyperparams\n",
    "    lora_r: int = 8,\n",
    "    lora_alpha: int = 16,\n",
    "    lora_dropout: float = 0.05,\n",
    "    lora_target_modules: List[str] = [\"\"],\n",
    "    # llm hyperparams\n",
    "    train_on_inputs: bool = True,  # if False, masks out inputs in loss\n",
    "    group_by_length: bool = False,  # faster, but produces an odd training loss curve\n",
    "    resume_from_checkpoint: str = None,  # either training checkpoint or final adapter\n",
    "    prompt_template_name: str = \"chemgpt\",  # The prompt template to use, will default to alpaca.\n",
    "):\n",
    "    \n",
    "    lora_target_modules = TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING[base_model]\n",
    "    if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0:\n",
    "        print(\n",
    "            f\"Training LoRA model with params:\\n\"\n",
    "            f\"base_model: {base_model}\\n\"\n",
    "            f\"data_path: {data_path}\\n\"\n",
    "            f\"output_dir: {output_dir}\\n\"\n",
    "            f\"batch_size: {batch_size}\\n\"\n",
    "            f\"micro_batch_size: {micro_batch_size}\\n\"\n",
    "            f\"num_epochs: {num_epochs}\\n\"\n",
    "            f\"learning_rate: {learning_rate}\\n\"\n",
    "            f\"cutoff_len: {cutoff_len}\\n\"\n",
    "            f\"lora_r: {lora_r}\\n\"\n",
    "            f\"lora_alpha: {lora_alpha}\\n\"\n",
    "            f\"lora_dropout: {lora_dropout}\\n\"\n",
    "            f\"lora_target_modules: {lora_target_modules}\\n\"\n",
    "            f\"train_on_inputs: {train_on_inputs}\\n\"\n",
    "            f\"group_by_length: {group_by_length}\\n\"\n",
    "            f\"resume_from_checkpoint: {resume_from_checkpoint or False}\\n\"\n",
    "            f\"prompt template: {prompt_template_name}\\n\"\n",
    "        )\n",
    "    assert (\n",
    "        base_model\n",
    "    ), \"Please specify a --base_model, e.g. --base_model='gpt2'\"\n",
    "    gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "\n",
    "    device_map = \"sequential\"\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "    #ddp = world_size != 1\n",
    "    ddp = False\n",
    "    if ddp:\n",
    "        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps // world_size\n",
    "    \n",
    "    #set up the model and tokenizer    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "    # might not be optimal, just trying to run the code\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model, \n",
    "        load_in_8bit=False,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map='sequential',\n",
    "    )    \n",
    "    def tokenize(prompt):\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=cutoff_len,\n",
    "            padding=True,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def tokenize_prompt(data_point):\n",
    "        full_prompt = data_point[\"prompt\"]+data_point[\"completion\"]\n",
    "        tokenized_full_prompt = tokenize(full_prompt)\n",
    "        return tokenized_full_prompt\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=lora_target_modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    train_data = Dataset.from_pandas(df_train).shuffle().map(tokenize_prompt)\n",
    "    val_data = Dataset.from_pandas(df_val).shuffle().map(tokenize_prompt)\n",
    "    test_data = Dataset.from_pandas(df_test).shuffle().map(tokenize_prompt)\n",
    "    \n",
    "    if resume_from_checkpoint:\n",
    "        # Check the available weights and load them\n",
    "        checkpoint_name = os.path.join(\n",
    "            resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "        )  # Full checkpoint\n",
    "        if not os.path.exists(checkpoint_name):\n",
    "            checkpoint_name = os.path.join(\n",
    "                resume_from_checkpoint, \"adapter_model.bin\"\n",
    "            )  # only LoRA model - LoRA config above has to fit\n",
    "            resume_from_checkpoint = (\n",
    "                False  # So the trainer won't try loading its state\n",
    "            )\n",
    "        # The two files above have a different name depending on how they were saved, but are actually the same.\n",
    "        if os.path.exists(checkpoint_name):\n",
    "            print(f\"Restarting from {checkpoint_name}\")\n",
    "            adapters_weights = torch.load(checkpoint_name)\n",
    "            model = set_peft_model_state_dict(model, adapters_weights)\n",
    "        else:\n",
    "            print(f\"Checkpoint {checkpoint_name} not found\")\n",
    "\n",
    "    model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n",
    "    \n",
    "    if not ddp and torch.cuda.device_count() > 1:\n",
    "        # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "        model.is_parallelizable = True\n",
    "        model.model_parallel = True\n",
    "   \n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=micro_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            warmup_steps=10,\n",
    "            num_train_epochs=num_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            fp16=True,\n",
    "            logging_steps=4,\n",
    "            optim=\"adamw_torch\",\n",
    "            evaluation_strategy=\"steps\",\n",
    "            save_strategy=\"steps\",\n",
    "            eval_steps=4,\n",
    "            save_steps=4,\n",
    "            output_dir=output_dir,\n",
    "            save_total_limit=3,\n",
    "            metric_for_best_model = 'eval_loss',\n",
    "            load_best_model_at_end=True,\n",
    "            ddp_find_unused_parameters=False if ddp else None,\n",
    "            group_by_length=group_by_length,\n",
    "        ),\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    old_state_dict = model.state_dict\n",
    "    print(old_state_dict)\n",
    "    print(model.state_dict)\n",
    "    model.state_dict = (\n",
    "        lambda self, *_, **__: get_peft_model_state_dict(\n",
    "            self, old_state_dict()\n",
    "        )\n",
    "    ).__get__(model, type(model))\n",
    "    \n",
    "    \n",
    "    if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "    print(\n",
    "        \"\\n If there's a warning about missing keys above, please disregard :)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import GenerationConfig\n",
    "#from utils.callbacks import Iteratorize, Stream\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\" \n",
    "    \n",
    "def generate(\n",
    "    df_test: pd.DataFrame,\n",
    "    load_8bit: bool = False,\n",
    "    base_model: str = \"gpt2\",\n",
    "    lora_weights: str = \"outputs\",\n",
    "    prompt_template: str = \"\",\n",
    "    cutoff_len: int = 256,\n",
    "):\n",
    "    #set up the model and tokenizer    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "    # might not be optimal, just trying to run the code\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    def tokenize(prompt):\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=cutoff_len,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    model= AutoModelForCausalLM.from_pretrained(\n",
    "        base_model, \n",
    "        load_in_8bit=False,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map='sequential',\n",
    "    )    \n",
    "    model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        lora_weights,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    if not load_8bit:\n",
    "        model.half()  # seems to fix bugs for some users.\n",
    "\n",
    "    model.eval()\n",
    "    if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    def evaluate(\n",
    "        prompt,\n",
    "        temperature=0,\n",
    "        top_p=0.75,\n",
    "        top_k=40,\n",
    "        num_beams=4,\n",
    "        max_new_tokens=128,\n",
    "        stream_output=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        inputs = tokenize(prompt)\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        generation_config = GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        generate_params = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"generation_config\": generation_config,\n",
    "            \"return_dict_in_generate\": True,\n",
    "            \"output_scores\": True,\n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "        }\n",
    "\n",
    "        # Without streaming\n",
    "        with torch.no_grad():\n",
    "            generation_output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                generation_config=generation_config,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "            )\n",
    "        s = generation_output.sequences[0]\n",
    "        output = tokenizer.decode(s)\n",
    "        #print(output)\n",
    "        return output\n",
    "\n",
    "    df_test[\"model_out\"] = df_test[\"prompt\"].map(lambda x: evaluate(x))\n",
    "    df_test[\"energy_out\"] = df_test[\"model_out\"].map(lambda x: float(x.replace('###','@@@').split('@@@')[1]))\n",
    "    df_test[\"energy_true\"] = df_test[\"completion\"].map(lambda x: float(x.split('@@@')[0]))\n",
    "    return(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1599169/3480655279.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"model_out\"] = df_test[\"prompt\"].map(lambda x: evaluate(x))\n",
      "/tmp/ipykernel_1599169/3480655279.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"energy_out\"] = df_test[\"model_out\"].map(lambda x: float(x.replace('###','@@@').split('@@@')[1]))\n",
      "/tmp/ipykernel_1599169/3480655279.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"energy_true\"] = df_test[\"completion\"].map(lambda x: float(x.split('@@@')[0]))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_train, df_val, df_test = get_data()\n",
    "    #train(df_train, df_val, base_model=\"gpt2\")\n",
    "    outs=generate(df_test.head(25), base_model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>model_out</th>\n",
       "      <th>energy_out</th>\n",
       "      <th>energy_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74606</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-2071.9989@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-2071.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56992</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1890.364@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1890.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16367</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1361.6393@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1361.6393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12238</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1466.7489@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1466.7489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1591.6076@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1591.6076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13203</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1405.7739@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1405.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82846</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1841.7596@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1841.7596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1599.1101@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1858.906</td>\n",
       "      <td>-1599.1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47472</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1743.1485@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1743.1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116647</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1798.0185@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1798.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104737</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1869.2652@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1869.2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12947</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1483.211@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1483.2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12181</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1784.618@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1858.906</td>\n",
       "      <td>-1784.6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121548</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1607.9761@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1607.9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65617</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1759.5296@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1759.5296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-2191.8958@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1858.906</td>\n",
       "      <td>-2191.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1741.6192@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1741.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41836</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1492.522@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1492.5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118167</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1979.7081@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1979.7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22273</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1627.3498@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1627.3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46552</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-2055.0035@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-2055.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122615</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1431.7735@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1431.7735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96842</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-2068.9536@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-2068.9536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42403</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1943.0791@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1943.0791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98367</th>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1913.2166@@@</td>\n",
       "      <td>What is the atomization energy in kcal/mol of ...</td>\n",
       "      <td>-1853.906</td>\n",
       "      <td>-1913.2166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt      completion  \\\n",
       "74606   What is the atomization energy in kcal/mol of ...   -2071.9989@@@   \n",
       "56992   What is the atomization energy in kcal/mol of ...    -1890.364@@@   \n",
       "16367   What is the atomization energy in kcal/mol of ...   -1361.6393@@@   \n",
       "12238   What is the atomization energy in kcal/mol of ...   -1466.7489@@@   \n",
       "42893   What is the atomization energy in kcal/mol of ...   -1591.6076@@@   \n",
       "13203   What is the atomization energy in kcal/mol of ...   -1405.7739@@@   \n",
       "82846   What is the atomization energy in kcal/mol of ...   -1841.7596@@@   \n",
       "25217   What is the atomization energy in kcal/mol of ...   -1599.1101@@@   \n",
       "47472   What is the atomization energy in kcal/mol of ...   -1743.1485@@@   \n",
       "116647  What is the atomization energy in kcal/mol of ...   -1798.0185@@@   \n",
       "104737  What is the atomization energy in kcal/mol of ...   -1869.2652@@@   \n",
       "12947   What is the atomization energy in kcal/mol of ...    -1483.211@@@   \n",
       "12181   What is the atomization energy in kcal/mol of ...    -1784.618@@@   \n",
       "121548  What is the atomization energy in kcal/mol of ...   -1607.9761@@@   \n",
       "65617   What is the atomization energy in kcal/mol of ...   -1759.5296@@@   \n",
       "13238   What is the atomization energy in kcal/mol of ...   -2191.8958@@@   \n",
       "18843   What is the atomization energy in kcal/mol of ...   -1741.6192@@@   \n",
       "41836   What is the atomization energy in kcal/mol of ...    -1492.522@@@   \n",
       "118167  What is the atomization energy in kcal/mol of ...   -1979.7081@@@   \n",
       "22273   What is the atomization energy in kcal/mol of ...   -1627.3498@@@   \n",
       "46552   What is the atomization energy in kcal/mol of ...   -2055.0035@@@   \n",
       "122615  What is the atomization energy in kcal/mol of ...   -1431.7735@@@   \n",
       "96842   What is the atomization energy in kcal/mol of ...   -2068.9536@@@   \n",
       "42403   What is the atomization energy in kcal/mol of ...   -1943.0791@@@   \n",
       "98367   What is the atomization energy in kcal/mol of ...   -1913.2166@@@   \n",
       "\n",
       "                                                model_out  energy_out  \\\n",
       "74606   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "56992   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "16367   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "12238   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "42893   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "13203   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "82846   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "25217   What is the atomization energy in kcal/mol of ...   -1858.906   \n",
       "47472   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "116647  What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "104737  What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "12947   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "12181   What is the atomization energy in kcal/mol of ...   -1858.906   \n",
       "121548  What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "65617   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "13238   What is the atomization energy in kcal/mol of ...   -1858.906   \n",
       "18843   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "41836   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "118167  What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "22273   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "46552   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "122615  What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "96842   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "42403   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "98367   What is the atomization energy in kcal/mol of ...   -1853.906   \n",
       "\n",
       "        energy_true  \n",
       "74606    -2071.9989  \n",
       "56992    -1890.3640  \n",
       "16367    -1361.6393  \n",
       "12238    -1466.7489  \n",
       "42893    -1591.6076  \n",
       "13203    -1405.7739  \n",
       "82846    -1841.7596  \n",
       "25217    -1599.1101  \n",
       "47472    -1743.1485  \n",
       "116647   -1798.0185  \n",
       "104737   -1869.2652  \n",
       "12947    -1483.2110  \n",
       "12181    -1784.6180  \n",
       "121548   -1607.9761  \n",
       "65617    -1759.5296  \n",
       "13238    -2191.8958  \n",
       "18843    -1741.6192  \n",
       "41836    -1492.5220  \n",
       "118167   -1979.7081  \n",
       "22273    -1627.3498  \n",
       "46552    -2055.0035  \n",
       "122615   -1431.7735  \n",
       "96842    -2068.9536  \n",
       "42403    -1943.0791  \n",
       "98367    -1913.2166  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcd70c591e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGdCAYAAAAWp6lMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtVklEQVR4nO3df3RU5YH/8c8MQyZJ85MYIGiQH1kISFkiR2MgtrDICasF6bfgYpe6qFXLCZxSWSwqkgaKoIjrrl/tthJMtilKUdbAQaJgk/0CJpi2hB9CKBSSKAZbjUmghCSdud8/MLNOMwkTmCGZh/frnHuO9z7PPPd57jM38/HOnYvNsixLAAAABrP3dAcAAACCjcADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADCeo6c70Fu43W598sknio6Ols1m6+nuAAAAP1iWpbNnz2rQoEGy2zu/jkPg+dInn3yi5OTknu4GAAC4DB999JFuuOGGTssJPF+Kjo6WdPGAxcTE9HBvAACAP5qampScnOz5HO8MgedL7V9jxcTEEHgAAAgxl7odhZuWAQCA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADj8eBBBJXLbemDU/U609is+r+0ql+UUwNjwnXr0H7qY7d1qPensxfUP7pjeW8QyD4Goq3uttGd+lfSv2DPZTDa96dNl9tS+R8/V9nJzyTZlDE8QbcNS+h179Ng8PeY+3sce/u5fjl8jUvSVT0el9tWKJ6zl4PAg6ApPlyn3G1HVNd4oUNZUmy4cqaP1rQxST7rfbW8NwhkHwPRVnfb6E79K+lfsOcyGO3702bx4Tot3XJIDefbPHX+b8kJxUX21Zr/8/Ve8z4NBn+Pub/Hsbef65fD17jiIvtKktd7JpjH43LbCsVz9nLZLMuyruoee6mmpibFxsaqsbGRf1oiAIoP12l+4e/V1ZvLJunhbwzVL/7fqQ712rP/z+be3ON/CDsby+X0MRBtdbeN7tS/kv4F8jhdrfb9aVOSflD4+y7b+c9e8D4NBn+Pub/HMZjvj57iz9+6dsE6Hpd7boTiOeuLv5/f3MODgHO5LeVuO+LXH4BXdncMO5I823K3HZHL3XOZvKuxdLePgWiru210p/6V9C+Qx8mXYLTvb5s5RYcv2VZPv0+Dwd/j0/pXt1/1frL1w159rl+O7vytk4JzPC733AjFc/ZKEXgQcB+cqvf5NdbfsiR19V63JNU1XtAHp+oD1rfuutRYutPHQLTV3Ta6U/9K+hfI4+RLMNr3t81Pz7Zesq2efp8Gg7/H55dl1X7VO9PUcsk6oXYM/f1b91WBPh6Xe26E4jl7pbiHBwH3p7Pd+wNwtdsLxr79qReItrrbRiD731XdYOwn2O2b9D4NBn/HU1N//qrvs7cIdn+D+XclFM/ZK0XgQcD1jw7v1e0FY9/+1AtEW91tI5D976puMPYT7PZNep8Gg7/jubFf5FXfZ28R7P4G8+9KKJ6zV4qvtBBwtw7tp6TYS7+JbZK6+mWiTRfv5m//eWdPaB9LZ93sTh8D0VZ32+hO/SvpXyCPky/BaN/fNgdEh12yrZ5+nwaDv8fnexlD/Ko3MMYZtPdHT7nUMfIl0Mfjcs+NUDxnr1RQA8+qVas0YcIERUZGKi4uzmediooKTZkyRXFxcYqPj1dWVpYOHDjgKa+urpbNZuuwlJeX+2zv9ddfl81m08yZM4MwIvijj92mnOmj/foj8NDtQ2WTOtRtX8+ZPrpHn9HRPpav9qldd/sYiLa620Z36l9J/wJ5nHwJRvv+tpl795hLttXT79Ng8Pf4hDnsftX7yYybLlkn1I5hV8fIl2Acj8s9N0LxnL1SQQ08ra2tmj17tubPn++z/Ny5c5o2bZoGDx6sffv2ac+ePYqOjlZWVpba2tq86u7atUt1dXWeZfz48R3aq66u1r/+67/q9ttvD8p44L9pY5L0s7k3d3qlJyk2XD+be7Mev3O0fjb3Zg38m3oDvyzvDT9TbR9LIPoYiLa620Z36l9J/wJ5nK5W+/60OW1Mkv5z7s2e56p8VXxkX2N/ki75f8z9PY69/Vy/HJ2NKz6yb4f3TLCOx+W2FYrn7JW4Ks/hyc/P16JFi9TQ0OC1/be//a1uueUW1dbWKjk5WZJ06NAhjR07VsePH1dKSoqqq6s1dOhQ7d+/X+PGjet0Hy6XS9/4xjf0wAMPaPfu3WpoaNBbb73ldx95Dk9w8KTl4LXFk5Z50vLVwpOWL40nLfdc+/5+fvdo4Dl79qyGDh2qBQsW6IknnpDL5dLjjz+ud999VwcPHpTD4fAEnuTkZF24cEEjRozQY489phkzZni1lZOTo4MHD+q///u/NW/evEsGnpaWFrW0/O/PApuampScnEzgAQAghITEgwejo6NVWlqqwsJCRUREKCoqSsXFxdqxY4ccjos/IIuKitK6deu0efNmbd++XZmZmZo5c6a2bt3qaWfPnj3Ky8vTK6+84ve+V69erdjYWM/SfoUJAACYp9uBZ+nSpT5vIv7qUlVV5Vdbzc3NevDBBzVx4kSVl5dr7969GjNmjO666y41NzdLkq677jo9+uijSk9P1y233KI1a9Zo7ty5Wrt2raSLV4m+973v6ZVXXtF1113n9zgef/xxNTY2epaPPvqou4cCAACEiG4/h2fx4sWaN29el3WGDRvmV1sbN25UdXW1ysrKZLfbPdvi4+NVVFSkOXPm+Hxdenq6du7cKUn64x//qOrqak2fPt1T7na7JUkOh0PHjh3T8OHDO7ThdDrldDr96icAAAht3Q48iYmJSkxMDMjOz58/L7vdLpvtf29eal9vDy2+VFZWKinp4t3dqampOnTokFf5smXLdPbsWf37v/87X1UBAIDgPmm5trZW9fX1qq2tlcvlUmVlpSQpJSVFUVFRmjp1qpYsWaLs7GwtXLhQbrdba9askcPh0OTJkyVJBQUFCgsLU1pamiRpy5Yt2rBhg9avXy9JCg8P15gx3s/JaH/mz99uBwAA16agBp7ly5eroKDAs94eWkpKSjRp0iSlpqZq27Ztys3NVUZGhux2u9LS0lRcXOy5giNJK1euVE1NjRwOh1JTU7Vp0ybNmjUrmF0HAAAGuSo/Sw8FPIcHAIDQExI/SwcAALgaCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMFNfCsWrVKEyZMUGRkpOLi4nzWqaio0JQpUxQXF6f4+HhlZWXpwIEDnvLq6mrZbLYOS3l5uadOfn5+h/Lw8PBgDg0AAISQoAae1tZWzZ49W/Pnz/dZfu7cOU2bNk2DBw/Wvn37tGfPHkVHRysrK0ttbW1edXft2qW6ujrPMn78eK/ymJgYr/KampqgjQsAAIQWRzAbz83NlXTxCowvVVVVqq+v14oVK5ScnCxJysnJ0dixY1VTU6OUlBRP3YSEBA0cOLDTfdlsti7LAQDAtatH7+EZOXKkEhISlJeXp9bWVjU3NysvL0+jRo3SkCFDvOrOmDFD/fv3V2ZmprZu3dqhrXPnzunGG29UcnKy7r77bn344Ydd7rulpUVNTU1eCwAAMFOPBp7o6GiVlpaqsLBQERERioqKUnFxsXbs2CGH4+LFp6ioKK1bt06bN2/W9u3blZmZqZkzZ3qFnpEjR2rDhg0qKipSYWGh3G63JkyYoI8//rjTfa9evVqxsbGepf0KEwAAMI/NsiyrOy9YunSpnnnmmS7rHD16VKmpqZ71/Px8LVq0SA0NDV71mpubNWnSJKWmpmrBggVyuVx67rnnVFVVpYqKCkVERPhs/7777tOpU6e0e/dun+VtbW0aNWqU7r33Xq1cudJnnZaWFrW0tHjWm5qalJycrMbGRsXExHQ5PgAA0Ds0NTUpNjb2kp/f3b6HZ/HixZo3b16XdYYNG+ZXWxs3blR1dbXKyspkt9s92+Lj41VUVKQ5c+b4fF16erp27tzZabt9+/ZVWlqaTpw40Wkdp9Mpp9PpVz8BAEBo63bgSUxMVGJiYkB2fv78edntdtlsNs+29nW3293p6yorK5WUlNRpucvl0qFDh3TnnXcGpJ8AACC0BfVXWrW1taqvr1dtba1cLpcqKyslSSkpKYqKitLUqVO1ZMkSZWdna+HChXK73VqzZo0cDocmT54sSSooKFBYWJjS0tIkSVu2bNGGDRu0fv16z35WrFih2267TSkpKWpoaNDatWtVU1Oj73//+8EcHgAACBFBDTzLly9XQUGBZ709tJSUlHju3dm2bZtyc3OVkZEhu92utLQ0FRcXe13BWblypWpqauRwOJSamqpNmzZp1qxZnvIvvvhCDz30kM6cOaP4+HiNHz9e77//vkaPHh3M4QEAgBDR7ZuWTeXvTU8AAKD38Pfzm39LCwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwXtACz6pVqzRhwgRFRkYqLi7OZ52KigpNmTJFcXFxio+PV1ZWlg4cOOApr66uls1m67CUl5d7tdPQ0KDs7GwlJSXJ6XRqxIgRevvtt4M1NAAAEGKCFnhaW1s1e/ZszZ8/32f5uXPnNG3aNA0ePFj79u3Tnj17FB0draysLLW1tXnV3bVrl+rq6jzL+PHjvfYzdepUVVdX64033tCxY8f0yiuv6Prrrw/W0AAAQIhxBKvh3NxcSVJ+fr7P8qqqKtXX12vFihVKTk6WJOXk5Gjs2LGqqalRSkqKp25CQoIGDhzos50NGzaovr5e77//vvr27StJGjJkSOAGAgAAQl6P3cMzcuRIJSQkKC8vT62trWpublZeXp5GjRrVIbDMmDFD/fv3V2ZmprZu3epVtnXrVmVkZCg7O1sDBgzQmDFj9PTTT8vlcnW5/5aWFjU1NXktAADATD0WeKKjo1VaWqrCwkJFREQoKipKxcXF2rFjhxyOixeeoqKitG7dOm3evFnbt29XZmamZs6c6RV6Tp48qTfeeEMul0tvv/22nnrqKa1bt04//elPu9z/6tWrFRsb61narzIBAADz2CzLsvytvHTpUj3zzDNd1jl69KhSU1M96/n5+Vq0aJEaGhq86jU3N2vSpElKTU3VggUL5HK59Nxzz6mqqkoVFRWKiIjw2f59992nU6dOaffu3ZKkESNG6MKFCzp16pT69OkjSXr++ee1du1a1dXVddrPlpYWtbS0eNabmpqUnJysxsZGxcTEdDlGAADQOzQ1NSk2NvaSn9/duodn8eLFmjdvXpd1hg0b5ldbGzduVHV1tcrKymS32z3b4uPjVVRUpDlz5vh8XXp6unbu3OlZT0pKUt++fT1hR5JGjRqlM2fOqLW1VWFhYT7bcTqdcjqdfvUVAACEtm4FnsTERCUmJgZkx+fPn5fdbpfNZvNsa193u92dvq6yslJJSUme9YkTJ2rjxo1yu92e4PSHP/xBSUlJnYYdAABwbQnaPTy1tbWqrKxUbW2tXC6XKisrVVlZqXPnzkmSpk6dqi+++ELZ2dk6evSoPvzwQ91///1yOByaPHmyJKmgoECvvfaaqqqqVFVVpaefflobNmzQwoULPfuZP3++6uvr9cMf/lB/+MMftH37dj399NPKzs4O1tAAAECICdrP0pcvX66CggLPelpamiSppKTEc+/Otm3blJubq4yMDNntdqWlpam4uNjrCs7KlStVU1Mjh8Oh1NRUbdq0SbNmzfKUJycn65133tGPfvQjjR07Vtdff71++MMf6sc//nGwhgYAAEJMt25aNpm/Nz0BAIDew9/Pb/4tLQAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeEENPKtWrdKECRMUGRmpuLg4n3UqKio0ZcoUxcXFKT4+XllZWTpw4ICnvLq6WjabrcNSXl7uqTNp0iSfde66665gDg8AAISIoAae1tZWzZ49W/Pnz/dZfu7cOU2bNk2DBw/Wvn37tGfPHkVHRysrK0ttbW1edXft2qW6ujrPMn78eE/Zli1bvMoOHz6sPn36aPbs2cEcHgAACBGOYDaem5srScrPz/dZXlVVpfr6eq1YsULJycmSpJycHI0dO1Y1NTVKSUnx1E1ISNDAgQN9ttOvXz+v9ddff12RkZEEHgAAIKmH7+EZOXKkEhISlJeXp9bWVjU3NysvL0+jRo3SkCFDvOrOmDFD/fv3V2ZmprZu3dplu3l5eZozZ46+9rWvdVqnpaVFTU1NXgsAADBTjwae6OholZaWqrCwUBEREYqKilJxcbF27Nghh+PixaeoqCitW7dOmzdv1vbt25WZmamZM2d2Gno++OADHT58WN///ve73Pfq1asVGxvrWdqvMAEAAPPYLMuyuvOCpUuX6plnnumyztGjR5WamupZz8/P16JFi9TQ0OBVr7m5WZMmTVJqaqoWLFggl8ul5557TlVVVaqoqFBERITP9u+77z6dOnVKu3fv7lD2yCOPqKysTAcPHuyyjy0tLWppafGsNzU1KTk5WY2NjYqJienytQAAoHdoampSbGzsJT+/u30Pz+LFizVv3rwu6wwbNsyvtjZu3Kjq6mqVlZXJbrd7tsXHx6uoqEhz5szx+br09HTt3Lmzw/a//OUvev3117VixYpL7tvpdMrpdPrVTwAAENq6HXgSExOVmJgYkJ2fP39edrtdNpvNs6193e12d/q6yspKJSUlddi+efNmtbS0aO7cuQHpHwAAMENQf6VVW1ur+vp61dbWyuVyqbKyUpKUkpKiqKgoTZ06VUuWLFF2drYWLlwot9utNWvWyOFwaPLkyZKkgoIChYWFKS0tTdLFn6Bv2LBB69ev77C/vLw8zZw5UwkJCcEcFgAACDFBDTzLly9XQUGBZ709tJSUlHju3dm2bZtyc3OVkZEhu92utLQ0FRcXe13BWblypWpqauRwOJSamqpNmzZp1qxZXvs6duyY9uzZo3fffTeYQwIAACGo2zctm8rfm54AAEDv4e/nN/+WFgAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgvKAFnlWrVmnChAmKjIxUXFyczzoVFRWaMmWK4uLiFB8fr6ysLB04cMBTXl1dLZvN1mEpLy/3aueFF17QyJEjFRERoeTkZP3oRz/ShQsXgjU0AAAQYoIWeFpbWzV79mzNnz/fZ/m5c+c0bdo0DR48WPv27dOePXsUHR2trKwstbW1edXdtWuX6urqPMv48eM9ZRs3btTSpUuVk5Ojo0ePKi8vT5s2bdITTzwRrKEBAIAQ4whWw7m5uZKk/Px8n+VVVVWqr6/XihUrlJycLEnKycnR2LFjVVNTo5SUFE/dhIQEDRw40Gc777//viZOnKjvfve7kqQhQ4bo3nvv1b59+wI4GgAAEMp67B6ekSNHKiEhQXl5eWptbVVzc7Py8vI0atQoDRkyxKvujBkz1L9/f2VmZmrr1q1eZRMmTNDvfvc7ffDBB5KkkydP6u2339add955tYYCAAB6uaBd4bmU6OholZaWaubMmVq5cqUk6e/+7u/0zjvvyOG42K2oqCitW7dOEydOlN1u15tvvqmZM2fqrbfe0owZMyRJ3/3ud/XZZ58pMzNTlmXpr3/9q37wgx9c8iutlpYWtbS0eNabmpqCNFIAANDTunWFZ+nSpT5vIv7qUlVV5Vdbzc3NevDBBzVx4kSVl5dr7969GjNmjO666y41NzdLkq677jo9+uijSk9P1y233KI1a9Zo7ty5Wrt2raed0tJSPf3003r55Zf1+9//Xlu2bNH27ds9Iaozq1evVmxsrGdp/1oNAACYx2ZZluVv5T//+c/6/PPPu6wzbNgwhYWFedbz8/O1aNEiNTQ0eNXLy8vTE088obq6OtntF3NXa2ur4uPjlZeXpzlz5vhs/6WXXtJPf/pT1dXVSZJuv/123XbbbV4hqLCwUA8//LDOnTvnaftv+brCk5ycrMbGRsXExHQ5RgAA0Ds0NTUpNjb2kp/f3fpKKzExUYmJiVfcOUk6f/687Ha7bDabZ1v7utvt7vR1lZWVSkpK6tDOV/Xp00eS1FWWczqdcjqdl9t9AAAQQoJ2D09tba3q6+tVW1srl8ulyspKSVJKSoqioqI0depULVmyRNnZ2Vq4cKHcbrfWrFkjh8OhyZMnS5IKCgoUFhamtLQ0SdKWLVu0YcMGrV+/3rOf6dOn6/nnn1daWprS09N14sQJPfXUU5o+fbon+AAAgGtb0ALP8uXLVVBQ4FlvDy0lJSWaNGmSUlNTtW3bNuXm5iojI0N2u11paWkqLi72uoKzcuVK1dTUyOFwKDU1VZs2bdKsWbM85cuWLZPNZtOyZct0+vRpJSYmavr06Vq1alWwhgYAAEJMt+7hMZm/3wECAIDew9/Pb/4tLQAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDxHT3fAZC63pQ9O1etPZy+of3S4bh3aT33stp7uFmAszrnehzlBb0HgCZLiw3XK3XZEdY0XPNuSYsOVM320po1J6sGeAWbinOt9mBP0JnylFQTFh+s0v/D3Xie5JJ1pvKD5hb9X8eG6HuoZYCbOud6HOUFvQ+AJMJfbUu62I7J8lLVvy912RC63rxoAuotzrvdhTtAbEXgC7INT9R3+j+arLEl1jRf0wan6q9cpwGCcc70Pc4LeiMATYH862/lJfjn1AHSNc673YU7QGxF4Aqx/dHhA6wHoGudc78OcoDci8ATYrUP7KSk2XJ396NKmi79SuHVov6vZLcBYnHO9D3OC3ihogWfVqlWaMGGCIiMjFRcX57NORUWFpkyZori4OMXHxysrK0sHDhzwlFdXV8tms3VYysvLPXXa2tq0YsUKDR8+XOHh4fr7v/97FRcXB2tYl9THblPO9NGS1OFkb1/PmT6a51AAAcI51/swJ+iNghZ4WltbNXv2bM2fP99n+blz5zRt2jQNHjxY+/bt0549exQdHa2srCy1tbV51d21a5fq6uo8y/jx4z1ly5Yt089//nO9+OKLOnLkiH7wgx/o29/+tvbv3x+soV3StDFJ+tncmzUw1vty7cDYcP1s7s08fwIIMM653oc5QW9jsywrqL8LzM/P16JFi9TQ0OC1/be//a1uueUW1dbWKjk5WZJ06NAhjR07VsePH1dKSoqqq6s1dOhQ7d+/X+PGjfPZ/qBBg/Tkk08qOzvbs+073/mOIiIiVFhY6Hc/m5qaFBsbq8bGRsXExHR7nL7whFHg6uKc632YEwSbv5/fPfak5ZEjRyohIUF5eXl64okn5HK5lJeXp1GjRmnIkCFedWfMmKELFy5oxIgReuyxxzRjxgxPWUtLi8LDvf8PIiIiQnv27Oly/y0tLWppafGsNzU1Xfmg/kYfu00ZwxMC3i4A3zjneh/mBL1Fj920HB0drdLSUhUWFioiIkJRUVEqLi7Wjh075HBczGFRUVFat26dNm/erO3btyszM1MzZ87U1q1bPe1kZWXp+eef1/Hjx+V2u7Vz505t2bJFdXVdP8Vz9erVio2N9SztV5kAAIB5uvWV1tKlS/XMM890Wefo0aNKTU31rHf2lVZzc7MmTZqk1NRULViwQC6XS88995yqqqpUUVGhiIgIn+3fd999OnXqlHbv3i1J+vOf/6yHHnpI27Ztk81m0/Dhw3XHHXdow4YNam5u7rSfvq7wJCcnB/QrLQAAEFxB+Upr8eLFmjdvXpd1hg0b5ldbGzduVHV1tcrKymS32z3b4uPjVVRUpDlz5vh8XXp6unbu3OlZT0xM1FtvvaULFy7o888/16BBg7R06dJL9sPpdMrpdPrVVwAAENq6FXgSExOVmJgYkB2fP39edrtdNtv/3rzWvu52uzt9XWVlpZKSOt7dHx4eruuvv15tbW168803dc899wSknwAAIPQF7abl2tpa1dfXq7a2Vi6XS5WVlZKklJQURUVFaerUqVqyZImys7O1cOFCud1urVmzRg6HQ5MnT5YkFRQUKCwsTGlpaZKkLVu2aMOGDVq/fr1nP/v27dPp06c1btw4nT59Wj/5yU/kdrv12GOPBWtoAAAgxAQt8CxfvlwFBQWe9fbQUlJS4rl3Z9u2bcrNzVVGRobsdrvS0tJUXFzsdQVn5cqVqqmpkcPhUGpqqjZt2qRZs2Z5yi9cuKBly5bp5MmTioqK0p133qlf/vKXnT7sEAAAXHuC/hyeUBGM5/AAAIDg8vfzm39LCwAAGI/AAwAAjNdjT1rubdq/2QvGE5cBAEBwtH9uX+oOHQLPl86ePStJPHEZAIAQdPbsWcXGxnZazk3LX3K73frkk08UHR3t9Wyg7mp/YvNHH33Ezc8hgPkKPcxZ6GHOQkuozZdlWTp79qwGDRrkeZCxL1zh+ZLdbtcNN9wQsPZiYmJC4o2Ci5iv0MOchR7mLLSE0nx1dWWnHTctAwAA4xF4AACA8Qg8AeZ0OpWTk8M/TBoimK/Qw5yFHuYstJg6X9y0DAAAjMcVHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfg8UN1dbUefPBBDR06VBERERo+fLhycnLU2trqqVNaWqq7775bSUlJ+trXvqZx48bpV7/6VYe2Nm/erNTUVIWHh+vrX/+63n77ba9yy7K0fPlyJSUlKSIiQnfccYeOHz8e9DGaxp85k6SDBw/q9ttvV3h4uJKTk/Xss892aIs5uzpWrVqlCRMmKDIyUnFxcT7rVFRUaMqUKYqLi1N8fLyysrJ04MABrzqBmFP4x585k6T8/HyNHTtW4eHh6t+/v7Kzs73KmbOrw9/5kqTPP/9cN9xwg2w2mxoaGrzKSktLdfPNN8vpdColJUX5+fkdXv/SSy9pyJAhCg8PV3p6uj744IPADeRyWbikHTt2WPPmzbPeeecd649//KNVVFRk9e/f31q8eLGnzqpVq6xly5ZZe/futU6cOGG98MILlt1ut7Zt2+aps3fvXqtPnz7Ws88+ax05csRatmyZ1bdvX+vQoUOeOmvWrLFiY2Ott956yzpw4IA1Y8YMa+jQoVZzc/NVHXOo82fOGhsbrQEDBlj//M//bB0+fNh67bXXrIiICOvnP/+5pw5zdvUsX77cev75561HH33Uio2N7VB+9uxZq1+/fta8efOsqqoq6/Dhw9Z3vvMda8CAAVZra6tlWYGbU/jnUnNmWZa1bt06a9CgQdavfvUr68SJE9aBAwesoqIiTzlzdvX4M1/t7r77busf//EfLUnWF1984dl+8uRJKzIy0nr00UetI0eOWC+++KLVp08fq7i42FPn9ddft8LCwqwNGzZYH374ofXQQw9ZcXFx1qeffhqkkfmHwHOZnn32WWvo0KFd1rnzzjut+++/37N+zz33WHfddZdXnfT0dOuRRx6xLMuy3G63NXDgQGvt2rWe8oaGBsvpdFqvvfZaAHt/bfrbOXv55Zet+Ph4q6WlxbPtxz/+sTVy5EjPOnN29b366qs+/xhXVFRYkqza2lrPtoMHD1qSrOPHj1uWFZg5Rfd1Nmf19fVWRESEtWvXrk5fy5xdfZ3NV7uXX37Z+uY3v2m99957HQLPY489Zt10001e9f/pn/7JysrK8qzfeuutVnZ2tmfd5XJZgwYNslavXh2wMVwOvtK6TI2NjerXr1+36pSVlemOO+7wqpOVlaWysjJJ0qlTp3TmzBmvOrGxsUpPT/fUweXzNR/f+MY3FBYW5tmWlZWlY8eO6YsvvvDUYc56h5EjRyohIUF5eXlqbW1Vc3Oz8vLyNGrUKA0ZMkRSYOYUgbNz50653W6dPn1ao0aN0g033KB77rlHH330kacOc9a7HDlyRCtWrNB//dd/+fyHOC81F62trfrd737nVcdut+uOO+7o8fki8FyGEydO6MUXX9QjjzzSaZ1f//rXqqio0P333+/ZdubMGQ0YMMCr3oABA3TmzBlPefu2zurg8vias87mo72sqzrM2dUXHR2t0tJSFRYWKiIiQlFRUSouLtaOHTvkcFz8d5ADMacInJMnT8rtduvpp5/WCy+8oDfeeEP19fWaOnWq53465qz3aGlp0b333qu1a9dq8ODBPut0NhdNTU1qbm7WZ599JpfL1Svn65oOPEuXLpXNZutyqaqq8nrN6dOnNW3aNM2ePVsPPfSQz3ZLSkp0//3365VXXtFNN910NYZyzQjWnCE4Lme+OtPc3KwHH3xQEydOVHl5ufbu3asxY8borrvuUnNzc5BHcu0I5Jy53W61tbXpP/7jP5SVlaXbbrtNr732mo4fP66SkpIgj+TaEMj5evzxxzVq1CjNnTs3yL3uGY6e7kBPWrx4sebNm9dlnWHDhnn++5NPPtHkyZM1YcIE/eIXv/BZ/3/+5380ffp0/du//Zvuu+8+r7KBAwfq008/9dr26aefauDAgZ7y9m1JSUledcaNG+fvsIwWyDnrbD7ay7qqw5z5p7vz1ZWNGzequrpaZWVlnkvtGzduVHx8vIqKijRnzpyAzOm1LpBz1n5OjB492rMtMTFR1113nWprayUF5jy8lgVyvn7zm9/o0KFDeuONNyRd/AWqJF133XV68sknlZub2+lcxMTEKCIiQn369FGfPn165Xxd04EnMTFRiYmJftU9ffq0Jk+erPHjx+vVV1/1+d1maWmpvvWtb+mZZ57Rww8/3KE8IyND7733nhYtWuTZtnPnTmVkZEiShg4dqoEDB+q9997zfFg2NTVp3759mj9/fvcHaKBAzllGRoaefPJJtbW1qW/fvpIuzsfIkSMVHx/vqcOcXb7uzNelnD9/Xna7XTabzbOtfd3tdksKzJxe6wI5ZxMnTpQkHTt2TDfccIMkqb6+Xp999pluvPFGSczZlQrkfL355pteV0srKir0wAMPaPfu3Ro+fLiki3Pxt48E+OpchIWFafz48Xrvvfc0c+ZMSRev9L333ntasGBBQPp52Xr0lukQ8fHHH1spKSnWlClTrI8//tiqq6vzLO1+85vfWJGRkdbjjz/uVf7555976uzdu9dyOBzWc889Zx09etTKycnx+RPnuLg4q6ioyDp48KB199138xPny+DPnDU0NFgDBgywvve971mHDx+2Xn/9dSsyMrLDz2GZs6ujpqbG2r9/v5Wbm2tFRUVZ+/fvt/bv32+dPXvWsizLOnr0qOV0Oq358+dbR44csQ4fPmzNnTvXio2NtT755BPLsgI3p/DPpebMsi7+vPmmm26y9u7dax06dMj61re+ZY0ePdrzKAHm7OrxZ76+qqSkpNOfpS9ZssQ6evSo9dJLL/n8WbrT6bTy8/OtI0eOWA8//LAVFxdnnTlzJthD7BKBxw+vvvqqJcnn0u5f/uVffJZ/85vf9Grr17/+tTVixAgrLCzMuummm6zt27d7lbvdbuupp56yBgwYYDmdTmvKlCnWsWPHrsYwjeLPnFmWZR04cMDKzMy0nE6ndf3111tr1qzp0BZzdnV0dg6VlJR46rz77rvWxIkTrdjYWCs+Pt76h3/4B6usrMyrnUDMKfzjz5w1NjZaDzzwgBUXF2f169fP+va3v+31aAHLYs6uFn/m66t8BZ727ePGjbPCwsKsYcOGWa+++mqH17744ovW4MGDrbCwMOvWW2+1ysvLAz+gbrJZ1pdf0gEAABjqmv6VFgAAuDYQeAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgvP8PxEoI1YL6LJ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(outs['energy_true'], outs['energy_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.17585074724844418, pvalue=0.4004486010967057)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(outs['energy_true'], outs['energy_out'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemGPT",
   "language": "python",
   "name": "chemgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
